{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "#import tensorflow.contrib.eager as tfe\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.tri as tri\n",
    "from scipy.special import betaln\n",
    "from scipy.stats import beta\n",
    "from scipy import stats\n",
    "from scipy.special import gamma as gamma_fun\n",
    "import scipy.special as spec\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "from deep_bayes.models import BayesFlow, SequenceNetwork\n",
    "from deep_bayes.training import train_online\n",
    "from deep_bayes.losses import maximum_likelihood_loss\n",
    "from deep_bayes.viz import plot_true_est_scatter, plot_true_est_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward model priors and generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, we have the following parameters:\n",
    "\n",
    "1. $\\alpha$ - inverse of incubation period (rate at which exposed move to infected)\n",
    "2. $\\beta$ - average contact rate in the population (I would model this in a more fine-grained manner\n",
    "3. $\\gamma$ - inverse of the mean infectous period (or rate at which infectious move to recovered)\n",
    "4. $d$ - death rate\n",
    "5. $\\rho$ - social distancing $\\in [0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(batch_size):\n",
    "    \"\"\"\n",
    "    Samples from the prior 'batch_size' times.\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    batch_size : int -- the number of samples to draw from the prior\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : np.ndarray of shape (batch_size, theta_dim) -- the samples batch of parameters\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    theta = np.random.uniform(low=[0.8, 0.1, 0.1, 0.01], \n",
    "                              high=[2.25, 1.0, 0.75, 0.4], size=(batch_size, 4))\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "def forward_model(params, t, init_values):\n",
    "    \"\"\"Forward model of the SIRD.\"\"\"\n",
    "    \n",
    "    S_0, E_0, I_0, D_0, R_0 = init_vals\n",
    "    S, E, I, D, R = [S_0], [E_0], [I_0], [D_0], [R_0]\n",
    "    \n",
    "    #extract time dependent rhos from params\n",
    "    rhos = params[0:6]\n",
    "    rhos_t = params[6:12]\n",
    "    rhos_t_asi = np.argsort(rhos_t)\n",
    "    rhos = rhos[rhos_t_asi]\n",
    "    rhos_t = rhos_t[rhos_t_asi].astype(np.int32)\n",
    "    \n",
    "    #construct dense rhos array\n",
    "    rho = np.ones((t.shape[0]))\n",
    "    for i in range(rhos_t.shape[0]):\n",
    "        rho[rhos_t[i]:] = rhos[i]    \n",
    "    \n",
    "    beta, alpha, gamma, d = params[12:]\n",
    "    dt = t[1] - t[0]\n",
    "    \n",
    "    for i,_ in enumerate(t[1:]):\n",
    "        \n",
    "        next_S = S[-1] + (-rho[i]*beta*S[-1]*I[-1])*dt\n",
    "        next_E = E[-1] + (rho[i]*beta*S[-1]*I[-1] - alpha*E[-1])*dt\n",
    "        next_I = I[-1] + (alpha*E[-1] - gamma*I[-1] - d*I[-1])*dt\n",
    "        next_R = R[-1] + (gamma*I[-1])*dt\n",
    "        next_D = D[-1] + (d*I[-1])*dt\n",
    "        \n",
    "        S.append(next_S)\n",
    "        E.append(next_E)\n",
    "        I.append(next_I)\n",
    "        D.append(next_D)\n",
    "        R.append(next_R)\n",
    "    return np.stack([rho, S, I, D, R]).T\n",
    "\n",
    "N = 10000\n",
    "init_vals = 1 - 1/N, 1/N, 0, 0, 0\n",
    "forward_model = partial(forward_model, init_values=init_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, t_obs=None, t_min=30, t_max=100, dt=1, to_tensor=True, **args):\n",
    "    \"\"\"\n",
    "    Runs the forward model 'batch_size' times by first sampling fromt the prior\n",
    "    theta ~ p(theta) and running x ~ p(x|theta).\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    batch_size : int -- the number of samples to draw from the prior\n",
    "    to_tensor  : boolean -- converts theta and x to tensors if True\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : tf.Tensor or np.ndarray of shape (batch_size, theta_dim) - the data gen parameters \n",
    "    x     : tf.Tensor of np.ndarray of shape (batch_size, n_obs, x_dim)  - the generated data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample from prior\n",
    "    # theta is a np.array of shape (batch_size, theta_dim)\n",
    "    theta = prior(batch_size)\n",
    "    \n",
    "    if t_obs is None:\n",
    "        t_obs = np.random.randint(t_min, t_max+1)\n",
    "    \n",
    "    t = np.linspace(0, t_obs, int(t_obs/dt) + 1)\n",
    "    \n",
    "    #generate 3x 1.0 rho at timestep 0\n",
    "    rhos0 = np.ones((batch_size,3))\n",
    "    rhos_t0 = np.zeros((batch_size,3))\n",
    "    \n",
    "    #generate 3 random rhos between 0.1 and 0.9\n",
    "    rhos = np.random.rand(batch_size,3)\n",
    "    rhos_t = np.random.randint(t_obs, size=(batch_size,3))\n",
    "    \n",
    "    # construct rhoparam matrix\n",
    "    rhos = np.concatenate([rhos0, rhos],axis=1)\n",
    "    rhos_t = np.concatenate([rhos_t0, rhos_t],axis=1)\n",
    "    rhoparams = np.concatenate([rhos,rhos_t],axis=1)\n",
    "    \n",
    "    #construct new theta\n",
    "    thetap = np.concatenate([rhoparams, theta],axis=1)\n",
    "    \n",
    "    # Generate data\n",
    "    # x is a np.ndarray of shape (batch_size, n_obs, x_dim)\n",
    "    x = np.apply_along_axis(forward_model, axis=1, arr=thetap, t=t, **args)\n",
    "    \n",
    "    # Convert to tensor, if specified \n",
    "    if to_tensor:\n",
    "        theta = tf.convert_to_tensor(theta, dtype=tf.float32)\n",
    "        rhoparams = tf.convert_to_tensor(rhoparams, dtype=tf.float32)\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "    return {'theta': theta, 'rhoparams':rhoparams, 'x': x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network hyperparameters\n",
    "inv_meta = {\n",
    "    'n_units': [128, 128, 128],\n",
    "    'activation': 'elu',\n",
    "    'w_decay': 0.00001,\n",
    "    'initializer': 'glorot_uniform'\n",
    "}\n",
    "n_inv_blocks = 6\n",
    "\n",
    "\n",
    "summary_meta = {\n",
    "    'lstm_units' :  64,\n",
    "    'conv_meta'  : [\n",
    "            dict(filters=64, kernel_size=5, strides=1, activation='elu', kernel_initializer='glorot_normal', padding='same'),\n",
    "            dict(filters=64, kernel_size=3, strides=1, activation='elu', kernel_initializer='glorot_normal', padding='same'),\n",
    "            dict(filters=64, kernel_size=3, strides=1, activation='elu', kernel_initializer='glorot_normal', padding='same'),\n",
    "            dict(filters=64, kernel_size=3, strides=1, activation='elu', kernel_initializer='glorot_normal', padding='same'),\n",
    "            dict(filters=64, kernel_size=3, strides=1, activation='elu', kernel_initializer='glorot_normal', padding='same'),\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Forward model hyperparameters\n",
    "param_names = [r'$\\beta$', r'$\\alpha$', r'$\\gamma$', r'$d$']\n",
    "theta_dim = len(param_names)\n",
    "n_test = 500\n",
    "\n",
    "\n",
    "# Training and optimizer hyperparameters\n",
    "ckpt_file = \"SEIDR\"\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "iterations_per_epoch = 1000\n",
    "n_samples_posterior = 2000\n",
    "clip_value = 5.\n",
    "\n",
    "starter_learning_rate = 0.0005\n",
    "\n",
    "#global_step = tfe.Variable(0, dtype=tf.int32)\n",
    "global_step = tf.Variable(0, dtype=tf.int32)\n",
    "\n",
    "decay_steps = 1000\n",
    "decay_rate = .99\n",
    "learning_rate = tf.compat.v1.train.exponential_decay(starter_learning_rate, global_step, \n",
    "                                           decay_steps, decay_rate, staircase=True)\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "data_gen = partial(data_generator, t_min=30, t_max=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 248 ms, sys: 2.53 ms, total: 251 ms\n",
      "Wall time: 251 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data = data_gen(n_test, t_obs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_net = SequenceNetwork(summary_meta)\n",
    "model = BayesFlow(inv_meta, n_inv_blocks, theta_dim, summary_net=summary_net, permute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile \n",
    "<p>In other words, run and plot performance of untrained networks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-68b613aaeedf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_true_est_scatter(model, test_data['x'], test_data['theta'], \n\u001b[0;32m----> 2\u001b[0;31m                       n_samples_posterior, param_names, figsize=(12, 3))\n\u001b[0m",
      "\u001b[0;32m~/Projects/Corona/BayesCorona/deep_bayes/viz.py\u001b[0m in \u001b[0;36mplot_true_est_scatter\u001b[0;34m(model, X_test, theta_test, n_samples, param_names, figsize, theta_approx_means, show, filename, font_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Initialize posterior means matrix, if nose specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtheta_approx_means\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtheta_approx_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# --- Plot true vs estimated posterior means on a single row --- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Corona/BayesCorona/deep_bayes/models.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, x, n_samples, to_numpy, training)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mz_normal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mtheta_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_normal_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Corona/BayesCorona/deep_bayes/models.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, z, x)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcINN\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcINNs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Corona/BayesCorona/deep_bayes/models.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, theta, x, inverse, log_det_J)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mu2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# Pre-Compute s1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Corona/BayesCorona/deep_bayes/models.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, theta, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1058\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/activations.py\u001b[0m in \u001b[0;36melu\u001b[0;34m(x, alpha)\u001b[0m\n\u001b[1;32m     89\u001b[0m         Linear Units (ELUs)](https://arxiv.org/abs/1511.07289)\n\u001b[1;32m     90\u001b[0m   \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36melu\u001b[0;34m(x, alpha)\u001b[0m\n\u001b[1;32m   4375\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4376\u001b[0m   \"\"\"\n\u001b[0;32m-> 4377\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4378\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36melu\u001b[0;34m(features, name)\u001b[0m\n\u001b[1;32m   3168\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   3169\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Elu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m         name, _ctx._post_execution_callbacks, features)\n\u001b[0m\u001b[1;32m   3171\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_true_est_scatter(model, test_data['x'], test_data['theta'], \n",
    "                      n_samples_posterior, param_names, figsize=(12, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(step=global_step, optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, './checkpoints/{}'.format(ckpt_file), max_to_keep=3)\n",
    "checkpoint.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ep in range(1, 10+1):\n",
    "    with tqdm(total=iterations_per_epoch, desc='Training epoch {}'.format(ep)) as p_bar:\n",
    "        losses = train_online(model=model, \n",
    "                              optimizer=optimizer, \n",
    "                              data_gen=data_generator, \n",
    "                              loss_fun=maximum_likelihood_loss, \n",
    "                              iterations=iterations_per_epoch,\n",
    "                              batch_size=batch_size,\n",
    "                              p_bar=p_bar,\n",
    "                              clip_value=clip_value,\n",
    "                              clip_method='value',\n",
    "                              global_step=global_step)\n",
    "        \n",
    "        plot_true_est_scatter(model, test_data['x'], test_data['theta'], \n",
    "                      n_samples_posterior, param_names, figsize=(12, 3))\n",
    "        \n",
    "        plot_true_est_posterior(model, 2000, param_names, font_size=8,\n",
    "                        X_test=test_data['x'][:5], \n",
    "                        theta_test=test_data['theta'][:5], figsize=(12, 8))\n",
    "\n",
    "        # Manage checkpoint\n",
    "        manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs = 100\n",
    "dt = 1    \n",
    "t = np.linspace(0, t_obs, int(t_obs/dt) + 1)\n",
    "params = np.array([1.2, 0.75, 0.2, 0.1, 0.6])\n",
    "ts = forward_model(params, t=t)\n",
    "labels = ['S', 'I', 'D', 'R']\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "for i in range(4):\n",
    "    ax.plot(ts[:, i], label=labels[i], lw=2)\n",
    "\n",
    "plt.legend()\n",
    "ts_t = tf.convert_to_tensor(ts[np.newaxis], dtype=tf.float32)\n",
    "\n",
    "\n",
    "theta_hat = model.sample(ts_t, 5000, to_numpy=True)\n",
    "\n",
    "f, axarr = plt.subplots(1, 5, figsize=(12, 3))\n",
    "for i in range(5):\n",
    "    \n",
    "    sns.distplot(theta_hat[:, i], ax=axarr[i], kde=False)\n",
    "    axarr[i].axvline(params[i], color='black')\n",
    "    \n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs = 30\n",
    "dt = 1    \n",
    "t = np.linspace(0, t_obs, int(t_obs/dt) + 1)\n",
    "params = np.array([1.2, 0.75, 0.2, 0.1, 0.99])\n",
    "ts = forward_model(params, t=t)\n",
    "labels = ['S', 'I', 'D', 'R']\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "for i in range(4):\n",
    "    ax.plot(ts[:, i], label=labels[i], lw=2)\n",
    "\n",
    "plt.legend()\n",
    "ts_t = tf.convert_to_tensor(ts[np.newaxis], dtype=tf.float32)\n",
    "\n",
    "\n",
    "theta_hat = model.sample(ts_t, 5000, to_numpy=True)\n",
    "\n",
    "f, axarr = plt.subplots(1, 5, figsize=(12, 3))\n",
    "for i in range(5):\n",
    "    \n",
    "    sns.distplot(theta_hat[:, i], ax=axarr[i], kde=False)\n",
    "    axarr[i].axvline(params[i], color='black')\n",
    "    \n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
